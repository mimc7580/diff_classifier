{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import os.path as op\n",
    "import diff_classifier.aws as aws\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track = [] # This is going to be the list of all filenames that will be included in the analysis\n",
    "\n",
    "remote_folder = '07_16_19_ECM_Breakdown' # The folder in AWS S3 containing the files to be analyzed\n",
    "bucket = 'mckenna.data' # The bucket in AWS S3 where the remote_folder is contained\n",
    "\n",
    "treatments = ['NT']\n",
    "slices = 3\n",
    "vids = 5\n",
    "\n",
    "for treat in treatments:\n",
    "    for slic in range(1, slices+1):\n",
    "        for num in range(1, vids+1):\n",
    "            to_track.append('{}_brain_2_slice_{}_vid_{}'.format(treat, slic, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track = [] # This is going to be the list of all filenames that will be included in the analysis\n",
    "\n",
    "remote_folder = '04_24_20_Obstruction_Scaling_Data' # The folder in AWS S3 containing the files to be analyzed\n",
    "bucket = 'mckenna.data' # The bucket in AWS S3 where the remote_folder is contained\n",
    "\n",
    "ages = ['P14', 'P21', 'P28', 'P35']\n",
    "slices = 3\n",
    "vids = 5\n",
    "\n",
    "for age in ages:\n",
    "    for slic in range(1, slices+1):\n",
    "        for num in range(1, vids+1):\n",
    "            to_track.append('{}_40nm_s{}_v{}'.format(age, slic, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track = [] # This is going to be the list of all filenames that will be included in the analysis\n",
    "\n",
    "remote_folder = '07_16_19_ECM_Breakdown' # The folder in AWS S3 containing the files to be analyzed\n",
    "bucket = 'mckenna.data' # The bucket in AWS S3 where the remote_folder is contained\n",
    "\n",
    "treatments = ['HYase','ChABC','NT']\n",
    "brains = 4\n",
    "slices = 3\n",
    "vids = 5\n",
    "\n",
    "for treat in treatments:\n",
    "    for brain in range(1, brains+1):\n",
    "        for slic in range(1, slices+1):\n",
    "            for num in range(1, vids+1):\n",
    "                to_track.append('{}_brain_{}_slice_{}_vid_{}'.format(treat, brain, slic, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track = [] # This is going to be the list of all filenames that will be included in the analysis\n",
    "\n",
    "remote_folder = '07_10_19_MPT_HA_solutions_trial2' # The folder in AWS S3 containing the files to be analyzed\n",
    "bucket = 'mckenna.data' # The bucket in AWS S3 where the remote_folder is contained\n",
    "NP_sizes = ['40']\n",
    "vids = 5 # this is the number of vids that were taken per condition (usually corresponding to different locations)\n",
    "mol_weights = ['low', 'med', 'high']\n",
    "\n",
    "for MW in mol_weights:\n",
    "    for size in NP_sizes:\n",
    "        for num in range(1, vids+1):\n",
    "            to_track.append('{}MW_{}nm_vid_{}'.format(MW, size, num))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track = [] # This is going to be the list of all filenames that will be included in the analysis\n",
    "\n",
    "remote_folder = '06_27_19_MPT_HA_solutions' # The folder in AWS S3 containing the files to be analyzed\n",
    "bucket = 'mckenna.data' # The bucket in AWS S3 where the remote_folder is contained\n",
    "NP_sizes = ['40']\n",
    "vids = 5 # this is the number of vids that were taken per condition (usually corresponding to different locations)\n",
    "mol_weights = ['low', 'med','high']\n",
    "\n",
    "for size in NP_sizes:\n",
    "    for MW in mol_weights:\n",
    "        for num in range(1, vids+1):\n",
    "            to_track.append('{}MW_'.format(MW)+'{}nm_vid_{}_{}MW_'.format(size, num, MW)+'{}nm_vid_{}'.format(size,num))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lowMW_40nm_vid_1_lowMW_40nm_vid_1',\n",
       " 'lowMW_40nm_vid_2_lowMW_40nm_vid_2',\n",
       " 'lowMW_40nm_vid_3_lowMW_40nm_vid_3',\n",
       " 'lowMW_40nm_vid_4_lowMW_40nm_vid_4',\n",
       " 'lowMW_40nm_vid_5_lowMW_40nm_vid_5',\n",
       " 'medMW_40nm_vid_1_medMW_40nm_vid_1',\n",
       " 'medMW_40nm_vid_2_medMW_40nm_vid_2',\n",
       " 'medMW_40nm_vid_3_medMW_40nm_vid_3',\n",
       " 'medMW_40nm_vid_4_medMW_40nm_vid_4',\n",
       " 'medMW_40nm_vid_5_medMW_40nm_vid_5',\n",
       " 'highMW_40nm_vid_1_highMW_40nm_vid_1',\n",
       " 'highMW_40nm_vid_2_highMW_40nm_vid_2',\n",
       " 'highMW_40nm_vid_3_highMW_40nm_vid_3',\n",
       " 'highMW_40nm_vid_4_highMW_40nm_vid_4',\n",
       " 'highMW_40nm_vid_5_highMW_40nm_vid_5']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'06_27_19_MPT_HA_solutions'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_track_40 = to_track[0:5]\n",
    "med_track_40 = to_track[5:10]\n",
    "high_track_40 = to_track[10:15]\n",
    "\n",
    "\n",
    "low_MW_40 = pd.DataFrame()\n",
    "med_MW_40 = pd.DataFrame()\n",
    "high_MW_40 = pd.DataFrame()\n",
    "\n",
    "um_px = 0.07\n",
    "fps = 33\n",
    "\n",
    "for prefix in low_track_40:\n",
    "    feat = 'features_{}.csv'.format(prefix)\n",
    "    aws.download_s3(remote_folder+'/'+feat, feat, bucket_name=bucket)\n",
    "    merged = pd.read_csv(feat)\n",
    "    low_MW_40 = pd.concat([low_MW_40, merged['Deff1']*um_px*um_px*fps], axis=0)\n",
    "    os.remove(feat)\n",
    "low_MW_40.to_csv('lowMW_40nm_trial_1_Deff.csv', mode='w', index = False)\n",
    "aws.upload_s3('lowMW_40nm_trial_1_Deff.csv', '04_24_20_Obstruction_Scaling_Data/lowMW_40nm_trial_1_Deff.csv', bucket_name='mckenna.data')\n",
    "os.remove('lowMW_40nm_trial_1_Deff.csv')\n",
    "\n",
    "for prefix in med_track_40:\n",
    "    feat = 'features_{}.csv'.format(prefix)\n",
    "    aws.download_s3(remote_folder+'/'+feat, feat, bucket_name=bucket)\n",
    "    merged = pd.read_csv(feat)\n",
    "    med_MW_40 = pd.concat([med_MW_40, merged['Deff1']*um_px*um_px*fps], axis=0)\n",
    "    os.remove(feat)\n",
    "med_MW_40.to_csv('medMW_40nm_trial_1_Deff.csv', mode='w', index = False)\n",
    "aws.upload_s3('medMW_40nm_trial_1_Deff.csv', '04_24_20_Obstruction_Scaling_Data/medMW_40nm_trial_1_Deff.csv', bucket_name='mckenna.data')\n",
    "os.remove('medMW_40nm_trial_1_Deff.csv')\n",
    "\n",
    "for prefix in high_track_40:\n",
    "    feat = 'features_{}.csv'.format(prefix)\n",
    "    aws.download_s3(remote_folder+'/'+feat, feat, bucket_name=bucket)\n",
    "    merged = pd.read_csv(feat)\n",
    "    high_MW_40 = pd.concat([high_MW_40, merged['Deff1']*um_px*um_px*fps], axis=0)\n",
    "    os.remove(feat)\n",
    "high_MW_40.to_csv('highMW_40nm_trial_1_Deff.csv', mode='w', index = False)\n",
    "aws.upload_s3('highMW_40nm_trial_1_Deff.csv', '04_24_20_Obstruction_Scaling_Data/highMW_40nm_trial_1_Deff.csv', bucket_name='mckenna.data')\n",
    "os.remove('highMW_40nm_trial_1_Deff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in to_track:\n",
    "    csv_file = '{}_stats.csv'.format(prefix)    \n",
    "    aws.download_s3(remote_folder+'/'+csv_file, csv_file, bucket_name=bucket)\n",
    "    original = pd.read_csv(csv_file)\n",
    "    converted = original*10\n",
    "    converted.to_csv(csv_file, mode='w', index = False)\n",
    "    aws.upload_s3(csv_file, '07_16_19_ECM_Breakdown/{}_stats.csv'.format(prefix), bucket_name='mckenna.data')\n",
    "#    os.remove(feat)\n",
    "    os.remove('{}_stats.csv'.format(prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning variables\n",
    "k = 1.3806503e-23 # m^2 kg s^-2 K\n",
    "T = 310.15 # K\n",
    "mu = 0.001 # kg m^-1 s^-1\n",
    "\n",
    "r_s = 26 # nm\n",
    "r_f = 3.5 # nm\n",
    "\n",
    "Do = k*T/(6*math.pi*mu*r_s*1e-9)*1e12 # um^2/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = '{}_Deff.csv'.format(to_track[0])\n",
    "Deff_vals = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_bar = (r_s+r_f)*(-4/math.pi*(math.log(Deff_vals['0'][3]/Do)))**(-1/2)-r_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.296268832904\n",
      "10.711682555683618\n"
     ]
    }
   ],
   "source": [
    "print(Deff_vals['0'][3])\n",
    "print(r_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
