{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the terms of the experiment are defined, such as the location of the files in S3 (bucket and folder name), and each of the video prefixes (everything before the file extension) that need to be tracked. \n",
    "\n",
    "Note that these videos should be similar-ish: while we can account for differences in mean intensities between videos, particle sizes should be approximately the same, and (slightly less important) particles should be moving at about the same order of magnitude speed. In this experiment, these videos were taken in 0.4% agarose gel at 100x magnification and 100.02 fps shutter speeds with nanoparticles of about 100nm in diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track = [] # This is going to be the list of all filenames that will be included in the analysis\n",
    "start_knot = 25 #Must be unique number for every run on Cloudknot.\n",
    "\n",
    "remote_folder = '06_11_19_MPT_particle_size_incubation_time' # The folder in AWS S3 containing the files to be analyzed\n",
    "bucket = 'mckenna.data' # The bucket in AWS S3 where the remote_folder is contained\n",
    "vids = 5 # this is the number of vids that were taken per condition (usually corresponding to different locations)\n",
    "times = ['1', '12', '24']\n",
    "\n",
    "for num in range(1, vids+1):\n",
    "    for time in times:\n",
    "        to_track.append('40nm_'+time+'h_vid_{}'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['40nm_1h_vid_1',\n",
       " '40nm_12h_vid_1',\n",
       " '40nm_24h_vid_1',\n",
       " '40nm_1h_vid_2',\n",
       " '40nm_12h_vid_2',\n",
       " '40nm_24h_vid_2',\n",
       " '40nm_1h_vid_3',\n",
       " '40nm_12h_vid_3',\n",
       " '40nm_24h_vid_3',\n",
       " '40nm_1h_vid_4',\n",
       " '40nm_12h_vid_4',\n",
       " '40nm_24h_vid_4',\n",
       " '40nm_1h_vid_5',\n",
       " '40nm_12h_vid_5',\n",
       " '40nm_24h_vid_5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The videos used with this analysis are fairly large (2048 x 2048 pixels and 651 frames), and in cases like this, the tracking algorithm can quickly eat up RAM. In this case, we chose to crop the videos to 512 x 512 images such that we can run our jobs on smaller EC2 instances with 16GB of RAM. \n",
    "\n",
    "Note that larger jobs can be made with user-defined functions such that splitting isn't necessary-- or perhaps an intermediate amount of memory that contains splitting, tracking, and msd calculation functions all performed on a single EC2 instance.\n",
    "\n",
    "The compiled functions in the knotlets module require access to buckets on AWS. In this case, we will be using a publicly (read-only) bucket. If users want to run this notebook on their own, will have to transfer files from nancelab.publicfiles to their own bucket, as it requires writing to S3 buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diff_classifier.knotlets as kn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell uses the function kn.split() to split all of the videos contained in 'to_track' into 16 smaller videos on which the actual tracking will be performed\n",
    "for prefix in to_track:\n",
    "    kn.split(prefix, remote_folder=remote_folder, bucket=bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking normally requires user input in the form of tracking parameters e.g. particle radius, linking max distance, max frame gap etc. When large datasets aren't required, each video can be manageably manually tracked using the TrackMate GUI. However, when datasets get large e.g. >20 videos, this can become extremely arduous. For videos that are fairly similar, you can get away with using similar tracking parameters across all videos. However, one parameter that is a little more noisy that the others is the quality filter value. Quality is a numerical value that approximate how likely a particle is to be \"real.\" \n",
    "\n",
    "In this case, I built a predictor that estimates the quality filter value based on intensity distributions from the input images. Using a relatively small training dataset (5-20 videos), users can get fairly good estimates of quality filter values that can be used in parallelized tracking workflows.\n",
    "\n",
    "Note: in the current setup, the predictor should be run in Python 3. While the code will run in Python 3, there are differences between the random number generators in Python2 and Python3 that I was not able to control for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import diff_classifier.imagej as ij\n",
    "import boto3\n",
    "import os.path as op\n",
    "import diff_classifier.aws as aws\n",
    "import diff_classifier.knotlets as kn\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regress_sys function should be run twice. When have_output is set to False, it generates a list of files that the user should manually track using Trackmate. Once the quality filter values are found, they can be used as input (y) to generate a regress object that can predict quality filter values for additional videos. Once y is assigned, set have_output to True and re-run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnum=20 #number of training datasets\n",
    "pref = []\n",
    "for num in to_track:                    \n",
    "    for row in range(0, 4):\n",
    "        for col in range(0, 4):\n",
    "            pref.append(\"{}_{}_{}\".format(num, row, col))\n",
    "\n",
    "y = np.array([2.39, 1.67, 1.55, 1.55, 1.52, 2.14, 1.93, 1.70, 1.94, 1.72, 1.52, 1.36, 3.20, 1.57, 1.97, 3.77, 1.69, 1.46, 2.21, 2.32])\n",
    "\n",
    "# Creates regression object based of training dataset composed of input images and manually\n",
    "# calculated quality cutoffs from tracking with GUI interface.\n",
    "regress = ij.regress_sys(remote_folder, pref, y, tnum, randselect=True,\n",
    "                         have_output=True, bucket_name=bucket)\n",
    "#Read up on how regress_sys works before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle object\n",
    "filename = 'regress.obj'\n",
    "with open(filename,'wb') as fp:\n",
    "    joblib.dump(regress,fp)\n",
    "\n",
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "aws.upload_s3(filename, remote_folder+'/'+filename, bucket_name=bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users should input all tracking parameters into the tparams object. Note that the quality value will be overwritten by values found using the quality predictor found above. Never change threshold, median intensity, or snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tparams1 = {'radius': 6.0, 'threshold': 0.0, 'do_median_filtering': False,\n",
    "           'quality': 10.0, 'xdims': (0, 511), 'ydims': (1, 511),\n",
    "           'median_intensity': 300.0, 'snr': 0.0, 'linking_max_distance': 15.0,\n",
    "           'gap_closing_max_distance': 17.0, 'max_frame_gap': 8,\n",
    "           'track_duration': 8.00}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloudknot setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloudknot requires the user to define a function that will be sent to multiple computers to run. In this case, the function knotlets.tracking will be used. We create a docker image that has the required installations (defined by the requirements.txt file from diff_classifier on Github, and the base Docker Image below that has Fiji pre-installed in the correct location.\n",
    "\n",
    "Note that I modify the Docker image below such that the correct version of boto3 is installed. For some reason, versions later than 1.5.28 error out, so I specified 5.28 as the correct version. Run my_image.build below to double-check that the Docker image is successfully built prior to submitting the job to Cloudknot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Before you run this next cell, you have to switch the kernel from Python 3 to Python 2, by doing the following: **\n",
    " 1. Kernel -> Restart and clear output\n",
    " 2. Kernel -> Change Kernel -> Python 2\n",
    " 3. Rerun cells required to run below cell\n",
    " \n",
    " ** One other important thing to note: \n",
    " - If you are performing the tracking, be sure that the my_image =  line is set to ck.DockerImage(func=kn.tracking,...\n",
    " - If you are performing the MSD/feature calculation (after you've carried out the tracking), be sure that the my_image = line is se to ck.DockerImage(func=kn.assemble_msds, ...\n",
    "     \n",
    "     ** following the tracking, before you run assemble_msds, you need to run the cell below that redefines all_maps as all_maps2. all_maps2 doesn't include the tparams1 input, and allows the kn.assemble_msds section to run properly. It won't work with the tparams input. **\n",
    "     \n",
    " Other than that, everything else should stay the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudknot as ck\n",
    "import os.path as op\n",
    "\n",
    "github_installs=('https://github.com/ccurtis7/diff_classifier.git')\n",
    "#my_image = ck.DockerImage(func=kn.tracking, base_image='arokem/python3-fiji:0.3', github_installs=github_installs)\n",
    "my_image = ck.DockerImage(func=kn.assemble_msds, base_image='arokem/python3-fiji:0.3', github_installs=github_installs)\n",
    "docker_file = open(my_image.docker_path)\n",
    "docker_string = docker_file.read()\n",
    "docker_file.close()\n",
    "\n",
    "req = open(op.join(op.split(my_image.docker_path)[0], 'requirements.txt'))\n",
    "req_string = req.read()\n",
    "req.close()\n",
    "\n",
    "new_req = req_string[0:req_string.find('\\n')-5]+'5.28'+ req_string[req_string.find('\\n'):]\n",
    "req_overwrite = open(op.join(op.split(my_image.docker_path)[0], 'requirements.txt'), 'w')\n",
    "req_overwrite.write(new_req)\n",
    "req_overwrite.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the execution of this cell, you have to check that the requirements.txt file has the first line 'boto3==1.5.28'.\n",
    "    - This file can be found in source -> diff-classifier -> notebooks -> development -> most recent file\n",
    "\n",
    "If it doesn't, you may have to change the line in the cell above that says 'new_req = reg_string[0:req_string.find('\\n')-4]+'5.28'+ reg_string[reg_string.find('\\n'):]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image.build(\"ChABC_slice_2\", image_name=\"test_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object all_maps is an iterable containing all the inputs sent to Cloudknot. This is useful, because if the user needs to modify some of the tracking parameters for a single video, this can be done prior to submission to Cloudknot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "all_maps = []\n",
    "for prefix in to_track:    \n",
    "    for i in range(0, 4):\n",
    "        for j in range(0, 4):\n",
    "            names.append('{}_{}_{}'.format(prefix, i, j))\n",
    "            all_maps.append(('{}_{}_{}'.format(prefix, i, j), remote_folder, bucket, 'regress.obj', 4, 4, (512, 512), tparams1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_knot = 77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cloudknot knot object sets up the compute environment which will run the code. Note that the name must be unique. Every time you submit a new knot, you should change the name. I do this with the variable start_knot, which I vary for each run.\n",
    "\n",
    "If larger jobs are anticipated, users can adjust both RAM and storage with the memory and image_id variables. Memory specifies the amount of RAM to be used. Users can build a customized AMI with as much space as they need, and enter the ID into image_ID. Read the Cloudknot documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot = ck.Knot(name='{}_b{}'.format('mike', start_knot),\n",
    "               docker_image = my_image,\n",
    "               memory = 16000,\n",
    "               resource_type = \"SPOT\",\n",
    "               bid_percentage = 100,\n",
    "               #image_id = 'ami-0e00afdf500081a0d', #May need to change this line\n",
    "               pars_policies=('AmazonS3FullAccess',))\n",
    "\n",
    "result_futures = knot.map(all_maps2, starmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot.clobber()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can track the progression of your run using the AWS Batch service online -- make sure you are looking at the right US Region.\n",
    "\n",
    "After the run, you might have some that fail. This usually happens when the computers get claimed by someone paying more money, and your job gets booted from the aws computers. Because of this, you will need to start a knw cloudknot knot and rerun those vids. The set up for that is shown below.\n",
    "\n",
    "Remember to clobber your knot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck.get_region()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a new all_maps2 array for any of the videos that failed to get analyzed the first time through. Double check that it worked well by printing the length of it immediately afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = []\n",
    "all_maps2 = []\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "\n",
    "for name in names:\n",
    "    try:\n",
    "        s3.Object(bucket, '{}/Traj_{}.csv'.format(remote_folder, name)).load()\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            missing.append(name)\n",
    "            all_maps2.append((name, remote_folder, bucket, 'regress.obj',\n",
    "                             4, 4, (512, 512), tparams1))\n",
    "        else:\n",
    "            print('Something else has gone wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_maps2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you change the name of your knot, either by changing the 'mike1' part or start_knot value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_maps2 = []\n",
    "for prefix in to_track:\n",
    "    all_maps2.append((prefix, remote_folder, bucket, (512, 512), 651, 4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can monitor the progress of their job in the Batch interface. Once the code is complete, users should clobber their knot to make sure that all AWS resources are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream analysis and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The knotlet.assemble_msds function (which can also potentially be submitted to Cloudknot as well for large jobs) calculates the mean squared displacements and trajectory features from the raw trajectory csv files found from the Cloudknot submission. It accesses them from the S3 bucket to which they were saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in to_track:\n",
    "    kn.assemble_msds(prefix, remote_folder, bucket='mckenna.data')\n",
    "    print('Successfully output msds for {}'.format(prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in to_track[5:7]:\n",
    "    kn.assemble_msds(prefix, remote_folder, bucket='ccurtis.data')\n",
    "    print('Successfully output msds for {}'.format(prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diff_classifier includes some useful imaging tools as well, including checking trajectories, plotting heatmaps of trajectory features, distributions of diffusion coefficients, and MSD plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diff_classifier.heatmaps as hm\n",
    "import diff_classifier.aws as aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['40nm_1h_vid_1',\n",
       " '40nm_12h_vid_1',\n",
       " '40nm_24h_vid_1',\n",
       " '40nm_1h_vid_2',\n",
       " '40nm_12h_vid_2',\n",
       " '40nm_24h_vid_2',\n",
       " '40nm_1h_vid_3',\n",
       " '40nm_12h_vid_3',\n",
       " '40nm_24h_vid_3',\n",
       " '40nm_1h_vid_4',\n",
       " '40nm_12h_vid_4',\n",
       " '40nm_24h_vid_4',\n",
       " '40nm_1h_vid_5',\n",
       " '40nm_12h_vid_5',\n",
       " '40nm_24h_vid_5']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vids in to_track:\n",
    "    prefix = vids\n",
    "    msds = 'msd_{}.csv'.format(prefix)\n",
    "    feat = 'features_{}.csv'.format(prefix)\n",
    "    aws.download_s3('{}/{}'.format(remote_folder, msds), msds, bucket_name=bucket)\n",
    "    aws.download_s3('{}/{}'.format(remote_folder, feat), feat, bucket_name=bucket)\n",
    "    hm.plot_trajectories(prefix, remote_folder=remote_folder, upload=True, figsize=(8, 8), bucket = bucket)\n",
    "    print('Successfully uploaded trajectory plot for {}'.format(prefix))\n",
    "    geomean, geoSEM = hm.plot_individual_msds(prefix, x_range=4, y_range=0.5, umppx=0.07, fps=50, upload=True, remote_folder=remote_folder, bucket = bucket)\n",
    "    aws.upload_s3('./geomean_{}.csv'.format(prefix), remote_folder+'/geomean_{}.csv'.format(prefix), bucket_name = bucket)\n",
    "    aws.upload_s3('./geoSEM_{}.csv'.format(prefix), remote_folder+'/geoSEM_{}.csv'.format(prefix), bucket_name = bucket)\n",
    "    aws.upload_s3('./msds_{}.png'.format(prefix), remote_folder+'/msds_{}.png'.format(prefix), bucket_name = bucket)\n",
    "    print('Successfully uploaded csv files for {}'.format(prefix))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geomean, geoSEM = hm.plot_individual_msds(prefix, x_range=4, y_range=0.5, umppx=0.07, fps=100, upload=True, remote_folder=remote_folder, bucket = bucket)\n",
    "aws.upload_s3('./geomean_{}.csv'.format(prefix), remote_folder+'/geomean_{}.csv'.format(prefix), bucket_name = bucket)\n",
    "aws.upload_s3('./geoSEM_{}.csv'.format(prefix), remote_folder+'/geoSEM_{}.csv'.format(prefix), bucket_name = bucket)\n",
    "aws.upload_s3('./msds_{}.png'.format(prefix), remote_folder+'/msds_{}.png'.format(prefix), bucket_name = bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.plot_heatmap(prefix, upload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.plot_particles_in_frame(prefix, y_range=500, upload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = to_track[0]\n",
    "\n",
    "msds = 'msd_{}.csv'.format(prefix)\n",
    "feat = 'features_{}.csv'.format(prefix)\n",
    "aws.download_s3('{}/{}'.format(remote_folder, msds), msds, bucket_name=bucket)\n",
    "aws.download_s3('{}/{}'.format(remote_folder, feat), feat, bucket_name=bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.plot_trajectories(prefix, remote_folder=remote_folder, upload=True, figsize=(8, 8), bucket = bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geomean, geoSEM = hm.plot_individual_msds(prefix, x_range=4, y_range=0.5, umppx=0.07, fps=100, upload=True, remote_folder=remote_folder, bucket = bucket)\n",
    "aws.upload_s3('./geomean_{}.csv'.format(prefix), remote_folder+'/geomean_{}.csv'.format(prefix), bucket_name = bucket)\n",
    "aws.upload_s3('./geoSEM_{}.csv'.format(prefix), remote_folder+'/geoSEM_{}.csv'.format(prefix), bucket_name = bucket)\n",
    "aws.upload_s3('./msds_{}.png'.format(prefix), remote_folder+'/msds_{}.png'.format(prefix), bucket_name = bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting msd files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import diff_classifier.aws as aws\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track = [] # This is going to be the list of all filenames that will be included in the analysis\n",
    "start_knot = 25 #Must be unique number for every run on Cloudknot.\n",
    "\n",
    "remote_folder = '06_11_19_MPT_particle_size_incubation_time' # The folder in AWS S3 containing the files to be analyzed\n",
    "bucket = 'mckenna.data' # The bucket in AWS S3 where the remote_folder is contained\n",
    "vids = 5 # this is the number of vids that were taken per condition (usually corresponding to different locations)\n",
    "times = ['1', '12', '24']\n",
    "\n",
    "for num in range(1, vids+1):\n",
    "    for time in times:\n",
    "        to_track.append('40nm_'+time+'h_vid_{}'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['40nm_1h_vid_1',\n",
       " '40nm_12h_vid_1',\n",
       " '40nm_24h_vid_1',\n",
       " '40nm_1h_vid_2',\n",
       " '40nm_12h_vid_2',\n",
       " '40nm_24h_vid_2',\n",
       " '40nm_1h_vid_3',\n",
       " '40nm_12h_vid_3',\n",
       " '40nm_24h_vid_3',\n",
       " '40nm_1h_vid_4',\n",
       " '40nm_12h_vid_4',\n",
       " '40nm_24h_vid_4',\n",
       " '40nm_1h_vid_5',\n",
       " '40nm_12h_vid_5',\n",
       " '40nm_24h_vid_5']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import diff_classifier.aws as aws\n",
    "import math\n",
    "\n",
    "for prefix in to_track:\n",
    "    filename = 'geomean_{}.csv'.format(prefix)\n",
    "    aws.download_s3(remote_folder+'/'+filename, filename, bucket_name=bucket)\n",
    "    local_name = filename\n",
    "    merged = pd.read_csv(local_name)\n",
    "    merged.columns = ['log']\n",
    "    merged['exp'] = 0\n",
    "    for rows in range(0,len(merged)):\n",
    "        log_value = merged['log'].iloc[rows]\n",
    "        exp_value = math.exp(log_value)\n",
    "        merged.loc[rows,'exp'] = exp_value\n",
    "    merged.to_csv('adj_'+filename, mode='w', index = False)\n",
    "    aws.upload_s3('./adj_'+filename, remote_folder+'/adj_'+filename, bucket_name = bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pref = 'adj_geomean_40nm_'\n",
    "\n",
    "time_points = ['1', '12', '24']\n",
    "num_vids = 5\n",
    "\n",
    "for time in time_points:\n",
    "    avg_df = pd.DataFrame()\n",
    "    for vid in range(1, num_vids+1):\n",
    "        exp = pd.read_csv(pref+'{}h_vid_{}.csv'.format(time, str(vid)))\n",
    "        avg_df = pd.concat([avg_df, exp['exp']], axis=1)\n",
    "    avg_df = avg_df.mean(axis = 1)\n",
    "    avg_df.to_csv('avg_'+pref+'{}h.csv'.format(time), mode='w', index = False)\n",
    "    aws.upload_s3('./avg_'+pref+'{}h.csv'.format(time), remote_folder+'/avg_'+pref+'{}h.csv'.format(time), bucket_name=bucket)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['40nm_1h_vid_1',\n",
       " '40nm_12h_vid_1',\n",
       " '40nm_24h_vid_1',\n",
       " '40nm_1h_vid_2',\n",
       " '40nm_12h_vid_2',\n",
       " '40nm_24h_vid_2',\n",
       " '40nm_1h_vid_3',\n",
       " '40nm_12h_vid_3',\n",
       " '40nm_24h_vid_3',\n",
       " '40nm_1h_vid_4',\n",
       " '40nm_12h_vid_4',\n",
       " '40nm_24h_vid_4',\n",
       " '40nm_1h_vid_5',\n",
       " '40nm_12h_vid_5',\n",
       " '40nm_24h_vid_5']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = pd.DataFrame()\n",
    "\n",
    "for prefix in to_track:\n",
    "    feat = 'features_{}.csv'.format(prefix)\n",
    "    aws.download_s3(remote_folder+'/'+feat, feat, bucket_name=bucket)\n",
    "    merged = pd.read_csv(feat)\n",
    "    combo = pd.concat([combo, merged['Deff1']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.34503766809246\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-cb3f0c104605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mbar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#plt.axvline(avg, color=colors[counter])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bar' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEGpJREFUeJzt3X+s3XV9x/HnS0Q0060whXVtkxLtMtHNYrpKwh8ycMoPYzGRBZZh51jqEkgg0c2if+iSkXTZlGl0LFWYZWNi44/QQN1ExBiTgQLWSqnOTht6aUfnVMSYsRTf++N+LzuU255z7znnnt7PfT6Sk/P9fs7ne877QO/rfu7nfL7fk6pCktSu5026AEnSeBn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ17vmTLiCJZ2xJ0jxVVfr1cUQvSY2b+Ih+hpdikKTBJX0H8s9wRC9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY3re2ZskhcCXwVO6fp/pqren+STwOuBJ7quf1RVuzJ9utaHgYuBn3ftD42jeEnHt3rzXc9s799yyQQr0SQNcgmEp4Dzq+pnSU4GvpbkC91jf1ZVnzmq/0XAmu72OuCm7l6SNAF9p25q2s+63ZO72/EuTLMBuLU77j5gWZLlw5cqSZqPgebok5yUZBdwGLi7qu7vHrohye4kNyY5pWtbARzoOXyqazv6OTcleWCI2iVJAxgo6Kvq6apaC6wE1id5NXA98JvA7wCnAe/pus92SbXn/AVQVVurat28qpYkDWxOq26q6ifAV4ALq+pQNz3zFPAPwPqu2xSwquewlcDBEdQqSZqHvkGf5GVJlnXbLwLeAHxnZt69W2VzKfBwd8gO4O2Zdg7wRFUdGkv1kqS+Bll1sxzYluQkpn8xbK+qO5N8OcnLmJ6q2QX8add/J9NLK/cxvbzyHaMvW5I0qL5BX1W7gbNnaT//GP0LuHr40iRJo+CZsZLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4Qb5KUNIisXrzXc9s799yycj7a3Ey6CU9w+Bvk1M3ktS4vkGf5IVJvp7kW0n2JPmLrv3MJPcn+V6STyd5Qdd+Sre/r3t89XjfgiTpeAYZ0T8FnF9VrwHWAhcmOQf4K+DGqloD/Bi4qut/FfDjqnoFcGPXT5I0IX2Dvqb9rNs9ubsVcD7wma59G3Bpt72h26d7/IIkGVnFkuZt9ea7nrlp6Rjow9gkJwEPAq8APgb8B/CTqjrSdZkCVnTbK4ADAFV1JMkTwK8CPzzqOTcBm4Z9A9JS5oenGsRAH8ZW1dNVtRZYCawHXjlbt+5+ttF7PaehamtVrRu0UEnS/Mxp1U1V/QT4CnAOsCzJzF8EK4GD3fYUsAqge/xXgB+NolhJ0twNsurmZUmWddsvAt4A7AXuBd7WddsI3NFt7+j26R7/clU9Z0Qv6cTnnH4bBpmjXw5s6+bpnwdsr6o7kzwC3J7kL4FvAjd3/W8G/jHJPqZH8pePoW5J0oD6Bn1V7QbOnqX9+0zP1x/d/j/AZSOpTpI0NM+MlaTGGfSS1DiDXpIaZ9BLUuO8TLG0iHgmrObDEb0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mN6xv0SVYluTfJ3iR7klzbtX8gyWNJdnW3i3uOuT7JviTfTfKmcb4BSdLxDfLFI0eAd1XVQ0leAjyY5O7usRur6m96Oyc5C7gceBXw68CXkvxGVT09ysIlSYPpO6KvqkNV9VC3/SSwF1hxnEM2ALdX1VNV9QNgH7B+FMVKOvGs3nzXs775SieeOc3RJ1kNnA3c3zVdk2R3kluSnNq1rQAO9Bw2xSy/GJJsSvLAnCuWJM3JwEGf5MXAZ4HrquqnwE3Ay4G1wCHggzNdZzm8ntNQtbWq1s25YmkJmRktO2LWMAYK+iQnMx3yt1XV5wCq6vGqerqqfgF8nP+fnpkCVvUcvhI4OLqSJUlzMciqmwA3A3ur6kM97ct7ur0VeLjb3gFcnuSUJGcCa4Cvj65kSdJcDLLq5lzgSuDbSXZ1be8Frkiylulpmf3AOwGqak+S7cAjTK/YudoVN5I0OX2Dvqq+xuzz7juPc8wNwA1D1CVJGhHPjJWkxhn0ktQ4g16SGmfQS1LjDHpJatwgyyslCeBZZ+ju33LJBCvRXDiil6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6KUJ8ktFtBAMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGtc36JOsSnJvkr1J9iS5tms/LcndSb7X3Z/atSfJR5LsS7I7yWvH/SYkScc2yIj+CPCuqnolcA5wdZKzgM3APVW1Brin2we4CFjT3TYBN428akknLE8CO/H0/eKRqjoEHOq2n0yyF1gBbADO67ptA74CvKdrv7WqCrgvybIky7vnkXQcfrGHxmFOc/RJVgNnA/cDZ8yEd3d/etdtBXCg57Cpru3o59qU5IG5lyxJmouBgz7Ji4HPAtdV1U+P13WWtnpOQ9XWqlo36OtLkuZnoKBPcjLTIX9bVX2ua348yfLu8eXA4a59CljVc/hK4OBoypUkzdUgq24C3AzsraoP9Ty0A9jYbW8E7uhpf3u3+uYc4Ann5yVpcvp+GAucC1wJfDvJrq7tvcAWYHuSq4BHgcu6x3YCFwP7gJ8D7xhpxZKkORlk1c3XmH3eHeCCWfoXcPWQdUmSRsQzYyWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJatwgJ0xJ0rx5Rc7Jc0QvSY0z6CWpcQa9tID89iVNgkEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjvASCpAXlJREWnkEvjYmBphNF36mbJLckOZzk4Z62DyR5LMmu7nZxz2PXJ9mX5LtJ3jSuwiVJgxlkjv6TwIWztN9YVWu7206AJGcBlwOv6o75uyQnjapYSdLc9Z26qaqvJlk94PNtAG6vqqeAHyTZB6wH/m3eFUpqmlNc4zfMqptrkuzupnZO7dpWAAd6+kx1bZKkCZlv0N8EvBxYCxwCPti1Z5a+NdsTJNmU5IF5vr4kaUDzWnVTVY/PbCf5OHBntzsFrOrpuhI4eIzn2ApsTTLrLwJpsXEKQieqeY3okyzv2X0rMLMiZwdweZJTkpwJrAG+PlyJkqRh9B3RJ/kUcB7w0iRTwPuB85KsZXpaZj/wToCq2pNkO/AIcAS4uqqeHk/pkqRBDLLq5opZmm8+Tv8bgBuGKUqSNDpe60aSGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOL9hSponr22jxcIRvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcyyulAbmcUouVI3pJapxBL0mNM+glqXHO0Usd5+DVqr4j+iS3JDmc5OGettOS3J3ke939qV17knwkyb4ku5O8dpzFS5L6G2RE/0ngo8CtPW2bgXuqakuSzd3+e4CLgDXd7XXATd29tOg4wp8M/7uPXt8RfVV9FfjRUc0bgG3d9jbg0p72W2vafcCyJMtHVawkae7m+2HsGVV1CKC7P71rXwEc6Ok31bVJkiZk1KtuMktbzdox2ZTkgRG/viTpKPMN+sdnpmS6+8Nd+xSwqqffSuDgbE9QVVurat08X1+SNKD5Bv0OYGO3vRG4o6f97d3qm3OAJ2ameCRJk9F31U2STwHnAS9NMgW8H9gCbE9yFfAocFnXfSdwMbAP+DnwjjHULEmag75BX1VXHOOhC2bpW8DVwxYlSRodL4EgSY0z6CWpcQa9JDXOoJekxhn0ktQ4L1OsJcuLZ2mpcEQvSY0z6CWpcQa9JDXOoJekxhn0ktQ4V91IOqG5Omp4juglqXEGvSQ1zqkbSYuKUzlz54hekhpn0EtS45y6UbP8E1+a5ohekhrniF7NcAS/NPn/vb+hgj7JfuBJ4GngSFWtS3Ia8GlgNbAf+P2q+vFwZUrDMxC0VI1i6uZ3q2ptVa3r9jcD91TVGuCebl+SNCHjmKPfAGzrtrcBl47hNSRJAxo26Av4YpIHk2zq2s6oqkMA3f3pQ76GJGkIw34Ye25VHUxyOnB3ku8MemD3i2FT346SpKEMNaKvqoPd/WHg88B64PEkywG6+8PHOHZrz7y+JGlM5h30SX4pyUtmtoE3Ag8DO4CNXbeNwB3DFqmlafXmu561UkbS/AwzdXMG8PkkM8/zz1X1L0m+AWxPchXwKHDZ8GVKkuZr3kFfVd8HXjNL+38DFwxTlCRpdLwEgk4YTtVI42HQS1LjvNaNFg0vYaBB+O/kuQx6LVr+QEuDMeg1EYa0tHCco5ekxhn0ktQ4g16SGuccvcbi6Dl45+SlyXFEL0mNc0QvYO6rYByxa7Hw36YjeklqnkEvSY1z6mYexv2n4Hyef+aYpfqnqaRjM+gHMOz89aj7D6LfHLrzltLSYdAvApMIZX8RSO0w6EegXyi2EJotvAdpqTLoJ8DQlCZnKf78GfSSlrSlEPxLIuiPXpFyrP3eNklqxdiCPsmFwIeBk4BPVNWWcb3WqC2G4Hc5pTQes/38L/aft7EEfZKTgI8BvwdMAd9IsqOqHhn1a7lsUJKOb1xnxq4H9lXV96vqf4HbgQ1jei1J0nGkqkb/pMnbgAur6k+6/SuB11XVNbP0HX0BkrREVFX69RnXiH62F35WoCfZlOSBMb2+JKkzrg9jp4BVPfsrgYO9HapqK7B1TK8/dkkeqKp1k65jIS3F9wxL8337ntsyrhH9N4A1Sc5M8gLgcmDHmF5LknQcYxnRV9WRJNcA/8r08spbqmrPOF5LknR8Y1tHX1U7gZ3jev4TwKKddhrCUnzPsDTft++5IWNZdSNJOnH4DVOS1DiDfgSSvDtJJXnppGsZtyR/neQ7SXYn+XySZZOuaVySXJjku0n2Jdk86XrGLcmqJPcm2ZtkT5JrJ13TQklyUpJvJrlz0rWMg0E/pCSrmL7Uw6OTrmWB3A28uqp+G/h34PoJ1zMWPZfxuAg4C7giyVmTrWrsjgDvqqpXAucAVy+B9zzjWmDvpIsYF4N+eDcCf85RJ4S1qqq+WFVHut37mD5HokVL7jIeVXWoqh7qtp9kOvhWTLaq8UuyErgE+MSkaxkXg34ISd4CPFZV35p0LRPyx8AXJl3EmKwADvTsT7EEQm9GktXA2cD9k61kQfwt04O1X0y6kHFZEtejH0aSLwG/NstD7wPeC7xxYSsav+O956q6o+vzPqb/1L9tIWtbQH0v49GqJC8GPgtcV1U/nXQ945TkzcDhqnowyXmTrmdcDPo+quoNs7Un+S3gTOBbSWB6CuOhJOur6j8XsMSRO9Z7npFkI/Bm4IJqd31u38t4tCjJyUyH/G1V9blJ17MAzgXekuRi4IXALyf5p6r6wwnXNVKuox+RJPuBdVX1w0nXMk7dF8p8CHh9Vf3XpOsZlyTPZ/rD5guAx5i+rMcftHyGd6ZHLNuAH1XVdZOuZ6F1I/p3V9WbJ13LqDlHr7n6KPAS4O4ku5L8/aQLGofuA+eZy3jsBba3HPKdc4ErgfO7/7e7upGuFjlH9JLUOEf0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMb9H+tCphl6X+NYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "replace_nan = combo.replace(0, np.nan)\n",
    "log_Deff = np.log(replace_nan[0].dropna())\n",
    "test_bins = np.linspace(-5, 5, 76)\n",
    "\n",
    "print(min(log_Deff))\n",
    "histogram, test_bins = np.histogram(log_Deff, bins=test_bins)\n",
    "#masked_Deff = ma.masked_equal(combo[0], np.nan)\n",
    "\n",
    "#masked_Deff['log'] = ma.log(masked_Deff)\n",
    "\n",
    "plt.rc('axes', linewidth=2)\n",
    "plot = histogram\n",
    "bins = test_bins\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:])/2\n",
    "bar[keys[counter]] = plt.bar(center, plot, align='center', width=width)\n",
    "#plt.axvline(avg, color=colors[counter])\n",
    "plt.xlabel(xlabel, fontsize=30)\n",
    "plt.ylabel(ylabel, fontsize=30)\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.102085\n",
       "1     -1.724942\n",
       "2     -1.060901\n",
       "3      0.411462\n",
       "4     -0.289031\n",
       "5      0.612743\n",
       "6      0.694384\n",
       "7      2.812448\n",
       "8     -2.142430\n",
       "9      0.875530\n",
       "10     0.778918\n",
       "13     1.999114\n",
       "14     2.526744\n",
       "15     1.392354\n",
       "17     1.503256\n",
       "18     0.543004\n",
       "19     1.230997\n",
       "20     1.522683\n",
       "21     2.206290\n",
       "22     3.242424\n",
       "23     1.402252\n",
       "24    -0.623051\n",
       "25     1.308327\n",
       "26     2.004697\n",
       "27     2.123449\n",
       "28     1.619382\n",
       "29     3.063285\n",
       "30     2.456219\n",
       "31     1.730261\n",
       "32     2.375392\n",
       "         ...   \n",
       "633    2.873554\n",
       "635    3.373928\n",
       "636    2.918808\n",
       "637    1.939241\n",
       "638    2.139340\n",
       "640    3.038015\n",
       "641   -0.134256\n",
       "643    1.190597\n",
       "645    2.974077\n",
       "646    3.018049\n",
       "647    3.406479\n",
       "648    2.766297\n",
       "650    2.586655\n",
       "651    1.204020\n",
       "652    3.515725\n",
       "654    3.138404\n",
       "655    1.849810\n",
       "656    2.420634\n",
       "657    1.740290\n",
       "658    2.334619\n",
       "660    2.035405\n",
       "661    1.154454\n",
       "662    2.771935\n",
       "663    2.211970\n",
       "664    1.493438\n",
       "665    2.395925\n",
       "666    1.921848\n",
       "667    2.080141\n",
       "668    1.739146\n",
       "670    2.703548\n",
       "Name: 0, Length: 6547, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Deff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
